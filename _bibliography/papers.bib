---
---
@INPROCEEDINGS{10094704,
abbr={ICASSP23},
  author={Ding, Siwen and Zhang, You and Duan, Zhiyao},
  booktitle={ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  title={SAMO: Speaker Attractor Multi-Center One-Class Learning For Voice Anti-Spoofing},
  year={2023},
  location={Rhode Island, Greece},
  abstract={Voice anti-spoofing systems are crucial auxiliaries for automatic speaker verification (ASV) systems. A major challenge is caused by unseen attacks empowered by advanced speech synthesis technologies. Our previous research on one-class learning has improved the generalization ability to unseen attacks by compacting the bona fide speech in the embedding space. However, such compactness lacks consideration of the diversity of speakers. In this work, we propose speaker attractor multi-center one-class learning (SAMO), which clusters bona fide speech around a number of speaker attractors and pushes away spoofing attacks from all the attractors in a high-dimensional embedding space. For training, we propose an algorithm for the co-optimization of bona fide speech clustering and bona fide/spoof classification. For inference, we propose strategies to enable anti-spoofing for speakers without enrollment. Our proposed system outperforms existing state-of-the-art single systems with a relative improvement of 38% on equal error rate (EER) on the ASVspoof2019 LA evaluation set.},
  volume={},
  number={},
  pages={1-5},
  keywords={Training;Representation learning;Performance evaluation;Codecs;Speech coding;Error analysis;Signal processing algorithms;Signal processing;Inference algorithms;Speech synthesis;anti-spoofing;one-class classification;speaker attractors;cluster representation learning;deepfake detection},
  doi={10.1109/ICASSP49357.2023.10094704},
  url={https://ieeexplore.ieee.org/abstract/document/10094704},
  dimensions={true},
  google_scholar_id={u5HHmVD_uO8C},
  video={https://www.youtube.com/watch?v=2szWD06keUg},
  additional_info={},
  code={https://github.com/sivannavis/samo},
  selected={true},
  }

@INPROCEEDINGS{10446118,
abbr={ICASSP24},
  author={Roman, Iran R. and Ick, Christopher and Ding, Sivan and Roman, Adrian S. and McFee, Brian and Bello, Juan P.},
  booktitle={ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  title={Spatial Scaper: A Library to Simulate and Augment Soundscapes for Sound Event Localization and Detection in Realistic Rooms},
  year={2024},
  location={Seoul, Korea},
  abstract={Sound event localization and detection (SELD) is an important task in machine listening. Major advancements rely on simulated data with sound events in specific rooms and strong spatio-temporal labels. SELD data is simulated by convolving spatialy-localized room impulse responses (RIRs) with sound waveforms to place sound events in a soundscape. However, RIRs require manual collection in specific rooms. We present SpatialScaper, a library for SELD data simulation and augmentation. Compared to existing tools, SpatialScaper emulates virtual rooms via parameters such as size and wall absorption. This allows for parameterized placement (including movement) of foreground and background sound sources. SpatialScaper also includes data augmentation pipelines that can be applied to existing SELD data. As a case study, we use SpatialScaper to add rooms to the DCASE SELD data. Training a model with our data led to progressive performance improves as a direct function of acoustic diversity. These results show that SpatialScaper is valuable to train robust SELD models.},
  volume={},
  number={},
  pages={1221-1225},
  keywords={Training;Location awareness;Acoustics;Libraries;Robustness;Task analysis;Speech processing;data augmentation;data simulation;room simulations;microphone arrays;spatial audio},
  doi={10.1109/ICASSP48485.2024.10446118},
  dimensions={true},
  google_scholar_id={d1gkVwhDpl0C},
  additional_info={},
  code={https://github.com/iranroman/SpatialScaper},
  selected={true},
  }

